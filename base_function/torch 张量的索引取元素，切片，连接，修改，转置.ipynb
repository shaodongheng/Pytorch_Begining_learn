{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量的索引，切片，连接，更改：  \n",
    "\n",
    "1.连接张量：------------------------------------torch.cat()\n",
    "2.分割特定数目的张量：--------------------------torch.chunk()\n",
    "\n",
    "3.按特定维度和索引取值：------------------------torch.gather()\n",
    "\n",
    "4.按索引取整行、整列：--------------------------torch.index_select()\n",
    "\n",
    "5.根据掩码（mask）取元素：----------------------torch.masked_select()\n",
    "\n",
    "6.缩小张量：------------------------------------torch.narrow()\n",
    "\n",
    "7.取非零元素的索引：----------------------------torch.nonzero()\n",
    "\n",
    "8.reshape张量：---------------------------------torch.reshape()\n",
    "\n",
    "9.分割矩阵：------------------------------------torch.split()\n",
    "\n",
    "10.去除维度为1的维度：--------------------------torch.squeeze()\n",
    "\n",
    "11.连接张量：-----------------------------------torch.stack()\n",
    "\n",
    "12.转置：---------------------------------------torch.t(input)\n",
    "\n",
    "13.取出指定位置元素：---------------------------torch.take()\n",
    "\n",
    "14.转置：---------------------------------------torch.transpose()\n",
    "\n",
    "15.将tensor切片成元组：-------------------------torch.unbind()\n",
    "\n",
    "16.增加维度：-----------------------------------torch.unsqueeze() \n",
    "\n",
    "17.按条件从两个tensor中挑选元素组成新tensor：---torch.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.连接张量：torch.cat(tensors, dim=0, out=None) → Tensor  \n",
    "张量的维度必须相同  \n",
    "dim:在哪个维度上连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2699,  1.1784, -0.1974],\n",
       "        [ 0.1379,  0.2558,  0.7817]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2699,  1.1784, -0.1974],\n",
       "        [ 0.1379,  0.2558,  0.7817],\n",
       "        [ 0.2699,  1.1784, -0.1974],\n",
       "        [ 0.1379,  0.2558,  0.7817],\n",
       "        [ 0.2699,  1.1784, -0.1974],\n",
       "        [ 0.1379,  0.2558,  0.7817]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x, x, x), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2699,  1.1784, -0.1974,  0.2699,  1.1784, -0.1974,  0.2699,  1.1784,\n",
       "         -0.1974],\n",
       "        [ 0.1379,  0.2558,  0.7817,  0.1379,  0.2558,  0.7817,  0.1379,  0.2558,\n",
       "          0.7817]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x, x, x), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.分割特定数目的张量：torch.chunk(tensor, chunks, dim=0) → List of Tensors  \n",
    "chunks：分割的数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.1673, -0.8886,  0.8499, -0.8105, -0.5820, -0.5908],\n",
       "         [-0.2695, -1.1172, -0.2423, -1.3921,  0.6245, -0.1917],\n",
       "         [-0.0477, -0.0491, -0.1908, -0.4689, -0.7814, -0.4261]]),\n",
       " tensor([[-1.6854,  1.0078,  0.1544,  0.0204,  0.9406,  0.5258],\n",
       "         [ 0.7861,  0.0200,  0.7481, -0.7727, -1.6728, -0.5807]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(5, 6)\n",
    "torch.chunk(a, 2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [4, 3]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[1,2],[3,4]])\n",
    "torch.gather(t, 1, torch.tensor([[0,0],[1,0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.按特定维度和索引取值：torch.gather(input, dim, index, out=None) → Tensor  \n",
    "dim：选取的维度  \n",
    "index：在该维度下的缩影位置  \n",
    "\n",
    "三维数据取法：  \n",
    "out[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0  \n",
    "out[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1  \n",
    "out[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [4, 3]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[1,2],[3,4]])\n",
    "torch.gather(t, 1, torch.tensor([[0,0],[1,0]]))#1：按行取，[0,0]：第一行的索引0的值，第一行的索引0的值，[1,0]:第二行索引1的值，第二行索引0的值  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4354, -0.2510],\n",
       "         [-0.1239, -0.6626]],\n",
       "\n",
       "        [[-0.5580,  0.3644],\n",
       "         [-2.0567, -0.0738]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2,2,2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4354, -0.2510],\n",
       "         [-0.1239, -0.0738]],\n",
       "\n",
       "        [[-0.4354, -0.2510],\n",
       "         [-2.0567, -0.6626]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(a,0,torch.tensor([[[0,0],[0,1]],[[0,0],[1,0]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4354, -0.2510],\n",
       "         [-0.1239, -0.6626]],\n",
       "\n",
       "        [[-0.5580,  0.3644],\n",
       "         [-2.0567, -0.0738]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.按索引取整行、整列：torch.index_select(input, dim, index, out=None) → Tensor  \n",
    "index：一维索引张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6252, -0.2069, -0.4375, -0.2583],\n",
       "        [ 0.9916, -0.2663,  0.1913, -0.7262],\n",
       "        [-0.6162,  0.5308,  0.4643,  0.9128]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6252, -0.2069, -0.4375, -0.2583],\n",
       "        [-0.6162,  0.5308,  0.4643,  0.9128],\n",
       "        [ 1.6252, -0.2069, -0.4375, -0.2583]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.tensor([0, 2, 0])\n",
    "torch.index_select(x, 0, indices)#按行取第0行，第2行，第0行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6252, -0.4375,  1.6252],\n",
       "        [ 0.9916,  0.1913,  0.9916],\n",
       "        [-0.6162,  0.4643, -0.6162]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(x, 1, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.根据掩码（mask）取元素：torch.masked_select(input, mask, out=None) → Tensor  \n",
    "mask的shape不需要和input相同，但数目要相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3555, -2.4503, -0.5795,  0.8988],\n",
       "        [ 1.3409,  0.6143, -0.0377,  0.0620],\n",
       "        [ 0.6315,  0.9311,  0.1348,  0.8666]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 1],\n",
       "        [1, 1, 0, 0],\n",
       "        [1, 1, 0, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = x.ge(0.5)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8988, 1.3409, 0.6143, 0.6315, 0.9311, 0.8666])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.masked_select(x, mask) #取出mask值为1的位置的元素"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.缩小张量：torch.narrow(input, dimension, start, length) → Tensor  \n",
    "start：开始取得起始位置  \n",
    "length：要取的数目，长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "torch.narrow(x, 0, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [5, 6],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.narrow(x, 1, 1, 2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0] = 1  #共享内存，取出的tensor变，原input也变\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.取非零元素的索引：torch.nonzero(input, out=None) → LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [4]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(torch.tensor([1, 1, 1, 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 1],\n",
       "        [2, 2],\n",
       "        [3, 3]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(torch.tensor([[0.6, 0.0, 0.0, 0.0],\n",
    "                                [0.0, 0.4, 0.0, 0.0],\n",
    "                                [0.0, 0.0, 1.2, 0.0],\n",
    "                                [0.0, 0.0, 0.0,-0.4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.reshape张量：torch.reshape(input, shape) → Tensor  \n",
    "元素数目和值相同，形状不同。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(4.)\n",
    "torch.reshape(a, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([[0, 1], [2, 3]])\n",
    "torch.reshape(b, (-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.分割矩阵：torch.split(tensor, split_size_or_sections, dim=0)  \n",
    "split_size_or_sections：单个块的大小，或一个列表表示每个块的大小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.去除维度为1的维度：torch.squeeze(input, dim=None, out=None) → Tensor  \n",
    "结果和input共享内存，所以元素值一变全变  \n",
    "dim：指定去除的维度，如果该维度不为1，则不操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2, 1, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(2, 1, 2, 1, 2)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.squeeze(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2, 1, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.squeeze(x, 0) #该维度不为1\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 1, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.squeeze(x, 1)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.连接张量：torch.stack(seq, dim=0, out=None) → Tensor  \n",
    "seq：要连接的张量序列  \n",
    "张量的size要相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.转置：torch.t(input) → Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2165, -1.1617,  0.2792],\n",
       "        [ 1.6782, -1.3492, -1.6946]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2165,  1.6782],\n",
       "        [-1.1617, -1.3492],\n",
       "        [ 0.2792, -1.6946]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.t(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.取出指定位置元素：torch.take(input, indices) → Tensor  \n",
    "将input当做一维向量来处理  \n",
    "indices：是在一维向量中的位置  \n",
    "取出的向量和indices同长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 8])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.tensor([[4, 3, 5],\n",
    "                        [6, 7, 8]])\n",
    "torch.take(src, torch.tensor([0, 2, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.转置：torch.transpose(input, dim0, dim1) → Tensor  \n",
    "共享内存  \n",
    "dim0:转置第一维  \n",
    "dim1：转置第二维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5855,  0.2253,  1.0154],\n",
       "        [-0.3529, -0.7420,  0.2859]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5855, -0.3529],\n",
       "        [ 0.2253, -0.7420],\n",
       "        [ 1.0154,  0.2859]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(x, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5855, -0.3529],\n",
       "        [ 0.2253, -0.7420],\n",
       "        [ 1.0154,  0.2859]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(x, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.将tensor切片成元组：torch.unbind(tensor, dim=0) → seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), tensor([4, 5, 6]), tensor([7, 8, 9]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.unbind(torch.tensor([[1, 2, 3],\n",
    "                            [4, 5, 6],\n",
    "                           [7, 8, 9]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.增加维度：torch.unsqueeze(input, dim, out=None) → Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4])\n",
    "torch.unsqueeze(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(x, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17.按条件从两个tensor中挑选元素组成新tensor：torch.where(condition, x, y) → Tensor  \n",
    "condition：条件为True从x中选，否则从y中选  \n",
    "x和y要是可以broadcastable的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4257,  0.7195],\n",
       "        [-0.3652,  0.9774],\n",
       "        [-1.1582, -0.1474]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 2)\n",
    "y = torch.ones(3, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.7195],\n",
       "        [1.0000, 0.9774],\n",
       "        [1.0000, 1.0000]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(x > 0, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
